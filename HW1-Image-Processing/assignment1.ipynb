{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1 - Getting started with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 1 is supposed to be a slightly more sophisticated starter homework into python, image processing, and linear algebra. You'll revise how to implement functions as external python-files and import and use them in jupyter notebooks.\n",
    "\n",
    "A big focus is also on learning how to use matplotlib since visualization skills are key skills you will need to acquire during 597. Computational photography includes two words, \"computation\" and \"photography.\" Of course, quantifying data and results with numbers is essential, however, photography - by its name - implies that it is a visual discipline. We're evaluating images, and it's utterly important to meticulously visualize every little step in the pipeline you are developing.\n",
    "\n",
    "In this course, we're not only interested in seeing input data and the processed results, but we also want to know what you're doing inside the pipeline. Please keep this in mind when you're designing the report for each homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few notes on Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this class is the first time you've ever used Python and Jupyter Notebook, please refer to the following tutorials before starting the homework.\n",
    "\n",
    "## Introduction to Python\n",
    "1. Excellent Documentation that shows you the essentials: https://www.w3schools.com/python/default.asp\n",
    "2. Interactive tutorial in browser:  https://www.learnpython.org/\n",
    "\n",
    "## Introduction to Jupyter\n",
    "In recent years, Jupyter Notebook/Labs have emerged as an essential tool for many data scientists and researchers. We recommend using Jupyter to test out small snippets of codes inside Jupyter Cells until they function correctly. Once tested out inside Jupyter, you can copy the complete function body over to the external .py cell for extensive testing.\n",
    "\n",
    "Here are a few references on Jupyter Notebook that might be helpful if you're new to it:\n",
    "1. https://realpython.com/jupyter-notebook-introduction/\n",
    "2. Video Tutorial: https://www.youtube.com/playlist?list=PL1m-6MPBNAZfF-El7BzqaOrCrTBRgH1Nk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:red\">Coding Tasks: </span>\n",
    "You will implement functions in the following python files:\n",
    "- src/imageprocessing.py\n",
    "- src/optics.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note for matlotlib: \n",
    "\n",
    "We're going to use matplotlib to plot a lot, and we're going to want to use colormap/colorbars to next to our plots, but they get buggy, and aren't usually the correct size to the graph. Use this following solution to fix it!\n",
    "\n",
    "https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning: Possibly Import of additional packages might be necessary\n",
    "\n",
    "You might need to import the packages in the src-files as well if you need them. If you want to use additional packages, feel free to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are a few packages to load that might come in handy for the homework\n",
    "\n",
    "# Note: If any of those packages cannot be loaded, simply install them using \n",
    "# PIP or Conda. Just google \"pip install PACKAGE name\", and you'll find more information on\n",
    "# how to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numpy is doing linear algebra and all the math for us\n",
    "import random # Random to create random numbers\n",
    "import matplotlib.pyplot as plt # matplotlib allows us to plot images and graphs\n",
    "import PIL # PIL is an image library\n",
    "import cv2 # cv2 is an image processing library\n",
    "import skimage # skimage is another image procssing library\n",
    "import skimage.transform\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on autoreload which will be important to update your modules \n",
    "# when you change them so that they work in the jupyter notebook\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the functions that you will have to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 3 different files inside the src folder: image processing, and optics\n",
    "# All 3 files contain functions that you will have to implement to pass this assignment\n",
    "\n",
    "# This notebook will guide you chronically through all functions, and whenever a function is not yet implemented, you will run into a \"RaiseNoteImplemented\" error\n",
    "# If this error occurs, navigate inside your Jupyter Lab to the python file \n",
    "# and read the function description that you'll have to implement then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.optics as optics\n",
    "import src.imageprocessing as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with some very simple image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of homework 1 you will learn basic image processing tasks. There are several functions you have to implement, and we have provided simple pytests that are checking that the functions are doing the job.\n",
    "\n",
    "However, once you try to visualize these images, you should immediately see if something goes wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image neeeds to be implemented\n",
    "I = ip.load_image(\"images/northwestern.jpg\") \n",
    "\n",
    "# According to the function description \n",
    "# following properties must be true when printed\n",
    "print(type(I)) # Should be <class 'numpy.ndarray'>\n",
    "print(I.dtype) # Should be float32\n",
    "print(I.shape) # Should be (1200, 2265, 3) for the chicago image\n",
    "print(I.max()) # Should be 1.0 (since it is scaled) for the chicago image\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I)\n",
    "plt.title(\"Image of Northwestern and Chicago Skyline\")\n",
    "ip.save_fig_as_png(\"Northwestern_Skyline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function that will save the current output \n",
    "# You find the description in ImageProcessing.py\n",
    "ip.save_fig_as_png(\"Northwestern_Skyline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the images, should be of size (250, 1000, 3)\n",
    "I_Chicago = ip.crop_chicago_from_northwestern(I)\n",
    "\n",
    "print(type(I_Chicago)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_Chicago.dtype) # Should be float32\n",
    "print(I_Chicago.shape) # Should be (250, 1000, 3)\n",
    "\n",
    "plt.imshow(I_Chicago)\n",
    "plt.title(\"Skyline of Chicago\")\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_chicago_gray = ip.convert_rgb2gray(I_Chicago)\n",
    "\n",
    "print(type(I_chicago_gray)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_chicago_gray.dtype) # Should be float32\n",
    "print(I_chicago_gray.shape) # Should be (250, 1000) or (250, 1000,1)\n",
    "\n",
    "plt.imshow(I_chicago_gray,cmap='gray')\n",
    "plt.title(\"Skyline of Chicago in Gray\")\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline_gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_downsampled = ip.downsample_by_scale_factor(I_chicago_gray,8)\n",
    "\n",
    "print(type(I_downsampled)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_downsampled.dtype) # Should be float32\n",
    "print(I_downsampled.shape) # Should be for downsampling facto of 8 (31, 125)\n",
    "\n",
    "plt.imshow(I_downsampled,cmap='gray')\n",
    "plt.title(\"A downsampled version of the Chicago skyline\")\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline_downsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# This should show the chicago skyline a subplot (2 x 2) for diufferent scale factors\n",
    "ip.plot_chicago_skyline(I_chicago_gray)\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline_downsampled_multiple_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final image should somewhat look like this:\n",
    "\n",
    "![Title](example_results/Chicago_Skyline_downsampled_multiple_images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Task: Implement the same procedure for your own image</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've implemented basic image processing tools, please download an image of your choice and do the same experiments as we've done here. I.e., that you should do image loading, cropping, converting from RGB to gray and show a subplot with different downsampling scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Image\n",
    "sharing_tech_img = ip.load_image('images/sharing_tech_logo.png')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(sharing_tech_img)\n",
    "plt.title(\"Image of Sharing Tech Ltd.\")\n",
    "\n",
    "ip.save_fig_as_png(\"Sharing_Tech_Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping image\n",
    "sharing_tech_logo = ip.crop_logo_from_image(sharing_tech_img)\n",
    "plt.imshow(sharing_tech_logo)\n",
    "plt.title(\"Sharing Tech Logo\")\n",
    "\n",
    "ip.save_fig_as_png(\"Sharing_Tech_Logo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo_gray = ip.convert_rgb2gray(sharing_tech_logo)\n",
    "\n",
    "plt.imshow(logo_gray,cmap='gray')\n",
    "plt.title(\"Sharing Tech Logo in Gray\")\n",
    "\n",
    "ip.save_fig_as_png(\"Logo_gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# This should show the chicago skyline a subplot (2 x 2) for diufferent scale factors\n",
    "ip.plot_chicago_skyline(logo_gray)\n",
    "\n",
    "ip.save_fig_as_png(\"Sharing_Tech_logo_downsampled_multiple_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Orange\"> Image Processing : Overlay Images</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will play around with simple image processing algorithms. In particular, we will first load an image of a dog with a transparent background. Subsequently, we will overlay this image on top of a picture of a natural landscape.\n",
    "\n",
    "First, we will play around with resizing and rotating images. Afterward, we will put our functions into a broader framework, which again is composed of several parts.\n",
    "\n",
    "This assignment aims to familiarize you with NumPy, skimage, cv2, and other packages that will come in handy in the future assignments.\n",
    "\n",
    "After we've learned these basic image processing tools, we will use the blur estimation functions discussed in Lecture 2 to estimate different blur kernels for background and foreground. We then simulate the effect of portrait photos that appear naturally in DLSR cameras or are simulated for nicer effects in modern smartphones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to revisit the function that can load an image that you should have already implemented at the beginning of the assignment.\n",
    "\n",
    "However, note that we are now dealing not only with 3 channels for RGB (Red-Green-Blue) but with a fourth channel, called alpha, which controls the transparency in each pixel.\n",
    "\n",
    "An alpha value of $0$ would correspond to no transparency, an alpha value of $1$ would be fully transparent.\n",
    "\n",
    "Luckily, matplotlib knows how to automatically deal with an alpha channel and take care of this when we want to display an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog = ip.load_image('images/dog2.png')\n",
    "print(I_dog.shape) # Should be (995, 800, 4)\n",
    "print(I_dog.dtype) # Should show 'float32'\n",
    "print(I_dog.max()) # Shoud be normalized to 1\n",
    "\n",
    "plt.imshow(I_dog)\n",
    "plt.title(\"The original image as it was saved\")\n",
    "# You should see a dog with a white background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pad Dog Image with Zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are padding the dog images because we might need to blur the dog image later. In order to not have boundary effects when blurring we're padding with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size = 100\n",
    "I_dog_padded = ip.pad_image(I_dog,pad_size)\n",
    "# Confirm that shape has changed\n",
    "print(I_dog_padded.shape) # (Should be 1195, 1000, 4) with pad_size = 100\n",
    "print(I_dog_padded.dtype) # Should still be a float32\n",
    "\n",
    "plt.imshow(I_dog_padded)\n",
    "plt.title(\"Padded Dog Image\")\n",
    "# You should see the same image of the dog but now there should be more white areas around the dog\n",
    "\n",
    "ip.save_fig_as_png(\"padded_dog_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The padded image should somewhat look like this:\n",
    "\n",
    "![Title](example_results/padded_dog_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resize Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to change the size of the dog image flexible to make a \"nicer\" composition of our final image. \n",
    "Sidenote: If we know the size of an average dog we can actually scale it so that it fits well with our actual camera paramters that we will choose later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog = ip.rescale(I_dog_padded,0.9)\n",
    "# I_dog = skimage.transform.rescale(I_dog_padded, scale=0.9, anti_aliasing=False, channel_axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(I_dog)\n",
    "plt.title(\"Rescaled Dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the background image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are loading the background image. If everything is implemented well, we should be able to reuse the function we already for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_canyon = ip.load_image('images/yosemite.jpg')\n",
    "# The image is pretty, large we should downscale it for easier processing\n",
    "I_canyon = ip.rescale(I_canyon,0.25)\n",
    "print(I_canyon.shape)\n",
    "print(I_canyon.dtype)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(I_canyon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The canyon image doesn't yet have an alpha channel. We need to add another axis. You'll have to implement a small method called \"add_alpha_channel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_canyon = ip.add_alpha_channel(I_canyon)\n",
    "print(I_canyon.shape)\n",
    "print(I_canyon.dtype)\n",
    "plt.imshow(I_canyon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us also visualize the alpha channel of the dog to make sur that it looks good/ as expected.\n",
    "# If this doesn't look like a segmentation mask, something is wrong and you need to revisit\n",
    "# your load_image function\n",
    "\n",
    "mask = I_dog[:,:,3]\n",
    "plt.imshow(mask,cmap='gray')\n",
    "plt.title(\"Alpha Channel of dog\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alpha channel should look somewhat like this for the dog\n",
    "\n",
    "![Title](example_results/alpha_channel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Overlay images of same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let us rescale the dog image because it is quite large\n",
    "I_dog_rescaled = ip.rescale(I_dog,0.5)\n",
    "I_dog_rescaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes let us crop out an image of the background which has exactly the\n",
    "# Same dimension as the rescaled dog\n",
    "x0 = 0\n",
    "y0 = 0\n",
    "I_overlay = I_canyon\n",
    "I_overlay = I_overlay[x0:x0+I_dog_rescaled.shape[0],y0:y0+I_dog_rescaled.shape[1],:]\n",
    "print(I_overlay.shape)\n",
    "plt.imshow(I_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you have to implement a function that overlays to images of the same size\n",
    "# where the second images contains the alpha-channel mask which you need\n",
    "# to account correctly for\n",
    "\n",
    "# WARNING: DO NOT SHRINK THE DOG\n",
    "# WARNING: DO NOT PLACE THE DOG ON TOP OF THE MOUNTAIN\n",
    "# WARNING: TAKE CARE OF THE BOUNDARIES.\n",
    "\n",
    "I_test_overlay = ip.overlay_two_images_of_same_size(I_overlay,I_dog_rescaled)\n",
    "\n",
    "# When you visualize this you should now see a Dog with the canyon image in the backgroud\n",
    "# If this looks weird you'll have to revisit either the load_image function or \n",
    "# the overlay_two_images_of_same_size function that you just implemented\n",
    "plt.imshow(I_test_overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overlayed image for same size should somewhat look like this\n",
    "\n",
    "![Title](example_results/overlayed_same_size.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlay imags of arbitrary sizes\n",
    "Now that we've learned how to overlay two images of the same size, we're going to look into how to overlay two images of arbitrary sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are some of the image data dimensions. Please think of why this might be problematic. This can help yoi when implementing the overlay function\n",
    "\n",
    "print(\"Dog shape: \" + str(I_dog.shape))\n",
    "print(\"Background shape: \" + str(I_canyon.shape))\n",
    "print(I_dog.shape > I_canyon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the location settings below the dogs feet shut be cut off since the feet would extend over the boundary of the canyon image\n",
    "# This is intened, because otherwise it would appear that the dog is floating in \"air\"\n",
    "# Feel free to play around with the location settings. For the image in your report try to avoid a \"floating\" dog\n",
    "# And have it appears as natural as possible\n",
    "I_canyon = ip.load_image('images/yosemite.jpg')\n",
    "# The image is pretty, large we should downscale it for easier processing\n",
    "I_canyon = ip.rescale(I_canyon,0.25)\n",
    "I_canyon = ip.add_alpha_channel(I_canyon)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I_canyon)\n",
    "\n",
    "x0 = 150\n",
    "y0 = 400\n",
    "I_new = ip.overlay_two_images(I_canyon,I_dog,[x0,y0])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I_new)\n",
    "plt.title(\"Overlayed Image without any focus settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_logo = ip.load_image('images/sharing_tech_logo.png')\n",
    "# The image is pretty, large we should downscale it for easier processing\n",
    "#I_canyon = ip.rescale(I_canyon,0.25)\n",
    "print(I_logo.shape)\n",
    "#I_logo = ip.add_alpha_channel(I_logo)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I_logo)\n",
    "\n",
    "I_dog2 = ip.load_image('images/dog.png')\n",
    "I_dog2 = ip.rescale(I_dog2,1.2)\n",
    "\n",
    "x0 = 600\n",
    "y0 = 700\n",
    "I_new2 = ip.overlay_two_images(I_logo,I_dog2,[x0,y0])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I_new2)\n",
    "plt.title(\"Overlayed Image without any focus settings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Task: Implement Dog overlayed with Yosemite</span>\n",
    "\n",
    "At this point you should see a dog that sits infront of a yosemite landscape. If this doesn't look well, please play around with the function we've asked you to implement. Don't proceed until this works well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hint:\n",
    "\n",
    "Your overlayed image should look something like this (Pay attention to the paws)\n",
    "\n",
    "![Title](example_results/overlayed_image_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Orange\"> Image Formation of a Camera System (e.g. DLSR) with Defocus </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be implementing a simpler version of the DoF simulator \n",
    "from https://dofsimulator.net/en/\n",
    "\n",
    "Please go there and play around with it to get a feeling for how DoF works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the formulas from the lecture that you'll need for this homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](defocus_blur.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{b}{D}=\\frac{|i' - i|}{i'}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lens Maker Formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{1}{i} + \\frac{1}{o} = \\frac{1}{f} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "b = \\frac{D}{i'} \\cdot \\lvert i' - i \\rvert \n",
    "   = D \\cdot \\left| \\frac{f(o - o')}{o'(o - f)} \\right|\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're using a DLSR with a Canon EF-mount for our simulation\n",
    "Information on Flange-Focal distance: https://en.wikipedia.org/wiki/Flange_focal_distance\n",
    "<br>\n",
    "Information on https://en.wikipedia.org/wiki/Canon_EF_lens_mount\n",
    "<br>\n",
    "Full frame Camera: https://en.wikipedia.org/wiki/Full-frame_digital_SLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All units will be in mm\n",
    "m = 1000 # m in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size_mm = np.array([24,36]) # mm\n",
    "print(sensor_size_mm)\n",
    "flange_focal_distance = 44.00 # mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Task:  Adjust the aspect ratio of the image</span>\n",
    "\n",
    "The image of the background has a specific aspect ratio given by the ratio of #pixels in x and y dimension.\n",
    "\n",
    "However, this aspect ratio might not match with the aspect ratio of the camere chip, which is given by actual size of the chip in x and y direction. We have stored these data for a common image format above in the variable sensor_size_mm.\n",
    "\n",
    "Please implement the crop_background_image_sensor_ratio function to align the background image with the actual sensor aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_canyon = ip.load_image('images/yosemite.jpg')\n",
    "# The image is pretty, large we should downscale it for easier processing\n",
    "I_canyon = ip.rescale(I_canyon,0.25)\n",
    "I_canyon = ip.add_alpha_channel(I_canyon)\n",
    "\n",
    "I_background = optics.crop_background_image_sensor_ratio(sensor_size_mm,I_canyon)\n",
    "plt.imshow(I_background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some definitions of your optical system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Length\n",
    "focal_length = 50 # mm\n",
    "# F-number\n",
    "N = 4\n",
    "# Aperture Diameter\n",
    "D = focal_length/N # mm\n",
    "# Focus Distance\n",
    "o_foc = 1.5*m # mm\n",
    "# Object Distance\n",
    "o_obj = 1.5*m # mm\n",
    "# Let's assume that the background is really far away, e.g. 1km away. \n",
    "o_background = 1000*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_object = optics.calc_blur_radius(focal_length,D,o_foc,o_obj)\n",
    "print(\"Blur Radius: \" + str(b_object) + \" mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_background =  optics.calc_blur_radius(focal_length,D,o_foc,o_background)\n",
    "print(\"Blur Radius: \" + str(b_background)+ \" mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate blur ratios\n",
    "Now we know the approximate blur radii for different image distances. \n",
    "What we have to do next, is the define how large the images actually are, so that we know what is the physical size of a pixel of the 2 images.\n",
    "\n",
    "This will help us to convert into how much we have to blur both images to approximate the correct amount of optical blur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define how large the images are\n",
    "\n",
    "angular_field_of_view = optics.calc_angular_field_of_view(sensor_size_mm,focal_length)\n",
    "print(\"Angular field of view: \" + str(angular_field_of_view) + \" deg\")\n",
    "field_of_view_object = optics.calc_field_of_view(sensor_size_mm,o_obj,focal_length)\n",
    "print(\"Field of View (Object): \" + str(field_of_view_object/m) + \" m\" )\n",
    "field_of_view_background = optics.calc_field_of_view(sensor_size_mm,o_background,focal_length)\n",
    "print(\"Field of View (Background) \" + str(field_of_view_background/m) + \" m\" )\n",
    "\n",
    "I_dog_real_height = 0.5*m\n",
    "I_dog_real_width = I_dog.shape[1]/I_dog.shape[0] * I_dog_real_height\n",
    "print(I_dog_real_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size_background = sensor_size_mm[0]/I_background.shape[0]\n",
    "pixel_size_foreground = sensor_size_mm[0]/I_dog.shape[0]\n",
    "\n",
    "print(\"Pixel Size - Background: \" + str(pixel_size_background))\n",
    "print(\"Pixel Size - Foreground: \" + str(pixel_size_foreground))\n",
    "\n",
    "\n",
    "blur_radius_background_pixel = b_background/pixel_size_background\n",
    "blur_radius_foreground_pixel = b_object/pixel_size_foreground\n",
    "\n",
    "print(\"Blur Radius Background: \" + str(blur_radius_background_pixel))\n",
    "print(\"Blur Radus Foreground: \" + str(blur_radius_foreground_pixel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate how much 1 pixel for background and foreground is in unit millimeters [mm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create disk-like filter footprint with given radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a radial distance map. It should be 0 in the center and the values increase radially symmetric\n",
    "# If the dimension is e.g. 100 pixels, the maximum value would be sqrt(2)*50 which is around 74\n",
    "\n",
    "R = optics.create_radial_distance_map(100)\n",
    "plt.imshow(R)\n",
    "plt.colorbar()\n",
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The radial distance map should look likle this:\n",
    "\n",
    "![Title](example_results/radial_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to calculate the point-spread-function\n",
    "# Read more on PSFs here: https://en.wikipedia.org/wiki/Point_spread_function\n",
    "\n",
    "PSF = optics.gaussian_psf(R,blur_radius_background_pixel)\n",
    "\n",
    "print(PSF.sum()) # should sum up to 1, otherwise energy is lost\n",
    "print(PSF.shape) # should be the same size as the radial map you generated earlire\n",
    "plt.imshow(PSF)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gaussian PSF shoiuld look like this:\n",
    "\n",
    "![Title](example_results/gaussian_psf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to conolve the background image with the Point Spread Function. \n",
    "# Please implement the convolution. Note that you're allowed to use external packages\n",
    "\n",
    "im_filtered = optics.convolve_image(I_background,PSF)\n",
    "\n",
    "print(I_background.shape)\n",
    "print(im_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_logo = ip.load_image('images/sharing_tech_logo.png')\n",
    "im_filtered2 = optics.convolve_image(I_logo,PSF)\n",
    "\n",
    "print(im_filtered.shape)\n",
    "plt.imshow(im_filtered2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a good place where you want to center the second image\n",
    "x0 = 150\n",
    "y0 = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_new = ip.overlay_two_images(im_filtered,I_dog,[x0,y0])\n",
    "plt.imshow(I_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 600\n",
    "y0 = 700\n",
    "\n",
    "I_new2 = ip.overlay_two_images(im_filtered2,I_dog2,[x0,y0])\n",
    "plt.imshow(I_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The final image should somewhat look like this:\n",
    "\n",
    "Checkpoints for you:\n",
    "- The dog should not float in the air\n",
    "- The background should be blurred\n",
    "- The object should not be blurred\n",
    "\n",
    "![Title](example_results/simulated_focus_image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
